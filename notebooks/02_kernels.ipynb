{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Design & Function Priors\n",
    "\n",
    "**Bayesian Optimisation Series · Notebook 2 of 3**\n",
    "\n",
    "The kernel is the *only* place where prior knowledge about the objective function enters the GP model. This notebook:\n",
    "1. Implements RBF, Matérn 5/2, Matérn 3/2, and Periodic kernels from scratch\n",
    "2. Visualises the correlation structure each kernel implies\n",
    "3. Shows how length-scale $\\ell$ controls smoothness\n",
    "4. Demonstrates kernel composition (sum and product)\n",
    "5. Computes the log marginal likelihood for hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy.special import gamma as gamma_fn\n",
    "\n",
    "rcParams['figure.figsize'] = (12, 5)\n",
    "rcParams['font.size'] = 12\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kernel Implementations\n",
    "\n",
    "All kernels take two matrices of shape `(n, d)` and return an `(n, m)` kernel matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cdist(X1, X2):\n",
    "    \"\"\"Pairwise Euclidean distances.\"\"\"\n",
    "    sq = np.sum(X1**2, 1).reshape(-1, 1) + np.sum(X2**2, 1).reshape(1, -1) - 2 * X1 @ X2.T\n",
    "    return np.sqrt(np.maximum(sq, 0))\n",
    "\n",
    "\n",
    "def rbf_kernel(X1, X2, l=1.0, sf=1.0):\n",
    "    r = _cdist(X1, X2)\n",
    "    return sf**2 * np.exp(-0.5 * (r / l)**2)\n",
    "\n",
    "\n",
    "def matern52_kernel(X1, X2, l=1.0, sf=1.0):\n",
    "    r = _cdist(X1, X2)\n",
    "    s = np.sqrt(5) * r / l\n",
    "    return sf**2 * (1 + s + s**2 / 3) * np.exp(-s)\n",
    "\n",
    "\n",
    "def matern32_kernel(X1, X2, l=1.0, sf=1.0):\n",
    "    r = _cdist(X1, X2)\n",
    "    s = np.sqrt(3) * r / l\n",
    "    return sf**2 * (1 + s) * np.exp(-s)\n",
    "\n",
    "\n",
    "def periodic_kernel(X1, X2, l=1.0, sf=1.0, period=1.0):\n",
    "    r = _cdist(X1, X2)\n",
    "    return sf**2 * np.exp(-2 * np.sin(np.pi * r / period)**2 / l**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kernel Correlation Profiles\n",
    "\n",
    "$k(r)$ vs distance $r = |x - x'|$ — each kernel decays differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.linspace(0, 5, 300).reshape(-1, 1)\n",
    "origin = np.zeros((1, 1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "kernels = [\n",
    "    ('RBF (C∞ smooth)', rbf_kernel, 'steelblue'),\n",
    "    ('Matérn 5/2 (C² smooth)', matern52_kernel, '#2ca02c'),\n",
    "    ('Matérn 3/2 (C¹ smooth)', matern32_kernel, '#d62728'),\n",
    "]\n",
    "\n",
    "for name, kern, color in kernels:\n",
    "    vals = kern(r, origin, l=1.0, sf=1.0).ravel()\n",
    "    ax.plot(r, vals, label=name, linewidth=2.5, color=color)\n",
    "\n",
    "ax.set_xlabel('Distance r = |x − x\\'|')\n",
    "ax.set_ylabel('k(r)')\n",
    "ax.set_title('Kernel Correlation Profiles — How Quickly Correlation Decays with Distance')\n",
    "ax.legend(fontsize=11)\n",
    "ax.axhline(0, color='gray', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GP Samples Under Different Kernels\n",
    "\n",
    "Same random seed, different kernels → different function classes. The kernel *is* the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-5, 5, 300).reshape(-1, 1)\n",
    "\n",
    "kernel_configs = [\n",
    "    ('RBF (ℓ=1.0)', lambda X1, X2: rbf_kernel(X1, X2, l=1.0)),\n",
    "    ('Matérn 5/2 (ℓ=1.0)', lambda X1, X2: matern52_kernel(X1, X2, l=1.0)),\n",
    "    ('Matérn 3/2 (ℓ=1.0)', lambda X1, X2: matern32_kernel(X1, X2, l=1.0)),\n",
    "    ('Periodic (p=2.0, ℓ=1.0)', lambda X1, X2: periodic_kernel(X1, X2, l=1.0, period=2.0)),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8), sharex=True, sharey=True)\n",
    "\n",
    "for ax, (name, kern_fn) in zip(axes.ravel(), kernel_configs):\n",
    "    K = kern_fn(X, X) + 1e-8 * np.eye(len(X))\n",
    "    L = np.linalg.cholesky(K)\n",
    "    samples = L @ np.random.randn(len(X), 4)\n",
    "\n",
    "    for i in range(4):\n",
    "        ax.plot(X, samples[:, i], alpha=0.7, linewidth=1.5)\n",
    "    ax.set_title(name, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "\n",
    "fig.suptitle('GP Prior Samples — Same Randomness, Different Kernels', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Length-Scale Controls Smoothness\n",
    "\n",
    "Large $\\ell$ → slow-varying, smooth functions. Small $\\ell$ → rapidly changing, wiggly functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_scales = [0.3, 1.0, 3.0]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4), sharey=True)\n",
    "\n",
    "for ax, ls in zip(axes, length_scales):\n",
    "    K = rbf_kernel(X, X, l=ls) + 1e-8 * np.eye(len(X))\n",
    "    L = np.linalg.cholesky(K)\n",
    "    samples = L @ np.random.randn(len(X), 4)\n",
    "\n",
    "    for i in range(4):\n",
    "        ax.plot(X, samples[:, i], alpha=0.7, linewidth=1.5)\n",
    "    ax.set_title(f'ℓ = {ls}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "\n",
    "axes[0].set_ylabel('f(x)')\n",
    "fig.suptitle('RBF Kernel — Effect of Length-Scale on Function Smoothness', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kernel Composition — Sum and Product\n",
    "\n",
    "Valid kernels can be combined:\n",
    "- **Sum** $k_1 + k_2$: models additive structure (e.g., trend + periodicity)\n",
    "- **Product** $k_1 \\cdot k_2$: models interaction (e.g., locally periodic = RBF × Periodic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gp(kern_fn, X, n_samples=3):\n",
    "    K = kern_fn(X, X) + 1e-8 * np.eye(len(X))\n",
    "    L = np.linalg.cholesky(K)\n",
    "    return L @ np.random.randn(len(X), n_samples)\n",
    "\n",
    "composed_kernels = [\n",
    "    ('RBF + Periodic\\n(trend + oscillation)',\n",
    "     lambda X1, X2: rbf_kernel(X1, X2, l=3.0, sf=0.5) + periodic_kernel(X1, X2, l=1.0, period=2.0, sf=0.5)),\n",
    "    ('RBF × Periodic\\n(locally periodic)',\n",
    "     lambda X1, X2: rbf_kernel(X1, X2, l=3.0, sf=1.0) * periodic_kernel(X1, X2, l=1.0, period=2.0, sf=1.0)),\n",
    "    ('Matérn 5/2 + RBF\\n(multi-scale)',\n",
    "     lambda X1, X2: matern52_kernel(X1, X2, l=0.5, sf=0.5) + rbf_kernel(X1, X2, l=3.0, sf=0.5)),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4), sharey=True)\n",
    "\n",
    "for ax, (name, kern_fn) in zip(axes, composed_kernels):\n",
    "    samples = sample_gp(kern_fn, X)\n",
    "    for i in range(3):\n",
    "        ax.plot(X, samples[:, i], alpha=0.7, linewidth=1.5)\n",
    "    ax.set_title(name, fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "\n",
    "axes[0].set_ylabel('f(x)')\n",
    "fig.suptitle('Kernel Composition — Building Complex Priors from Simple Kernels', fontsize=15, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Log Marginal Likelihood — Hyperparameter Selection\n",
    "\n",
    "$$\\log p(\\mathbf{y} | X, \\theta) = -\\frac{1}{2} \\mathbf{y}^\\top (K + \\sigma_n^2 I)^{-1} \\mathbf{y} - \\frac{1}{2} \\log |K + \\sigma_n^2 I| - \\frac{n}{2} \\log 2\\pi$$\n",
    "\n",
    "This balances data fit (first term) against model complexity (second term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_marginal_likelihood(X_train, y_train, l, sf, noise_var=0.01):\n",
    "    n = len(X_train)\n",
    "    K = rbf_kernel(X_train, X_train, l=l, sf=sf) + noise_var * np.eye(n)\n",
    "    L = np.linalg.cholesky(K)\n",
    "    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y_train))\n",
    "\n",
    "    data_fit = -0.5 * y_train @ alpha\n",
    "    complexity = -np.sum(np.log(np.diag(L)))\n",
    "    const = -0.5 * n * np.log(2 * np.pi)\n",
    "\n",
    "    return data_fit + complexity + const\n",
    "\n",
    "\n",
    "true_fn = lambda x: np.sin(x) + 0.5 * np.cos(2.5 * x)\n",
    "X_train = np.array([-3.5, -2.0, -0.5, 0.8, 2.0, 3.2, 4.0]).reshape(-1, 1)\n",
    "y_train = true_fn(X_train.ravel()) + 0.1 * np.random.randn(len(X_train))\n",
    "\n",
    "ls_range = np.linspace(0.1, 5.0, 100)\n",
    "lml_values = [log_marginal_likelihood(X_train, y_train, l=l, sf=1.0) for l in ls_range]\n",
    "\n",
    "best_l = ls_range[np.argmax(lml_values)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(ls_range, lml_values, linewidth=2.5, color='steelblue')\n",
    "ax.axvline(best_l, color='#d62728', linestyle='--', linewidth=1.5, label=f'optimal ℓ = {best_l:.2f}')\n",
    "ax.set_xlabel('Length-scale ℓ')\n",
    "ax.set_ylabel('Log Marginal Likelihood')\n",
    "ax.set_title('Hyperparameter Selection via Log Marginal Likelihood')\n",
    "ax.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal length-scale: ℓ = {best_l:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Previous:** [Notebook 1 — GP Surrogate](./01_gp_surrogate.ipynb) · **Next:** [Notebook 3 — Acquisition Functions & Full BO Loop](./03_acquisition_functions.ipynb)\n",
    "\n",
    "**Back to article:** [Bayesian Optimisation — Mathematical Deep Dive](https://omkarray.com/bayesian-optimization.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}